name: "ECS Task Run"
description: "Run an ECS task with configuration from an existing service"
author: Ilya Khrustalev <ilya.khrustalev@gmail.com>

branding:
  icon: "play"
  color: "orange"

inputs:
  cluster_arn:
    description: "ARN of the ECS cluster"
    required: true
  service_name:
    description: "Name of the ECS service to copy configuration from"
    required: true
  command:
    description: "Command to override in the task"
    required: true
  wait:
    description: "Wait for task completion"
    required: false
    default: "true"
  stream_logs:
    description: "Stream CloudWatch logs while task is running"
    required: false
    default: "true"
  shell:
    description: "Use shell for the command"
    required: false
    default: "true"
  timeout:
    description: "Timeout in seconds (0 = no timeout)"
    required: false
    default: "0"

outputs:
  task_arn:
    description: "ARN of the started task"
    value: ${{ steps.run-task.outputs.task_arn }}
  task_id:
    description: "ID of the started task"
    value: ${{ steps.run-task.outputs.task_id }}
  exit_code:
    description: "Exit code of the task"
    value: ${{ steps.wait.outputs.exit_code }}

runs:
  using: "composite"
  steps:
    - name: Get service configuration
      id: service-config
      shell: bash
      run: |
        set -euo pipefail
        echo "::group::Get service configuration"

        # Get service details
        SERVICE_JSON=$(aws ecs describe-services \
          --cluster "${{ inputs.cluster_arn }}" \
          --services "${{ inputs.service_name }}" \
          --query 'services[0]' \
          --output json)

        # Extract task definition ARN
        TASK_DEF_ARN=$(echo "$SERVICE_JSON" | jq -r '.taskDefinition')
        echo "task_definition=$TASK_DEF_ARN" >> $GITHUB_OUTPUT

        # Extract network configuration (full object, not just awsvpcConfiguration)
        NETWORK_CONFIG=$(echo "$SERVICE_JSON" | jq -c '.networkConfiguration')
        echo "network_config=$NETWORK_CONFIG" >> $GITHUB_OUTPUT

        # Extract launch type or capacity provider strategy
        LAUNCH_TYPE=$(echo "$SERVICE_JSON" | jq -r '.launchType // "FARGATE"')
        echo "launch_type=$LAUNCH_TYPE" >> $GITHUB_OUTPUT

        # Extract platform version if exists
        PLATFORM_VERSION=$(echo "$SERVICE_JSON" | jq -r '.platformVersion // "LATEST"')
        echo "platform_version=$PLATFORM_VERSION" >> $GITHUB_OUTPUT

        echo "Service configuration:"
        echo "Task Definition: $TASK_DEF_ARN"
        echo "Network Config: $NETWORK_CONFIG"
        echo "Launch Type: $LAUNCH_TYPE"
        echo "Platform Version: $PLATFORM_VERSION"

        echo "::endgroup::"

    - name: Parse command into container overrides
      id: parse-command
      shell: bash
      env:
        COMMAND: ${{ inputs.command }}
        SHELL_OPT: ${{ inputs.shell }}
      run: |
        # Convert command string to JSON array
        if [ "$SHELL_OPT" == "false" ]; then
          IFS=' ' read -ra CMD_ARRAY <<< "$COMMAND"
          COMMAND_JSON=$(printf '%s\n' "${CMD_ARRAY[@]}" | jq -R . | jq -s .)
        elif [ "$SHELL_OPT" == "true" ]; then
          COMMAND_JSON=$(jq -n --arg cmd "$COMMAND" '["/bin/sh", "-c", $cmd]')
        else
          COMMAND_JSON=$(jq -n --arg shell "$SHELL_OPT" --arg cmd "$COMMAND" '[$shell, "-c", $cmd]')
        fi

        # Get container name from task definition
        TASK_DEF_JSON=$(aws ecs describe-task-definition \
          --task-definition "${{ steps.service-config.outputs.task_definition }}" \
          --query 'taskDefinition' \
          --output json)

        CONTAINER_NAME=$(echo "$TASK_DEF_JSON" | jq -r '.containerDefinitions[0].name')

        # Create container overrides (compact JSON for GitHub Actions)
        OVERRIDES=$(jq -n -c \
          --arg name "$CONTAINER_NAME" \
          --argjson cmd "$COMMAND_JSON" \
          '{containerOverrides: [{name: $name, command: $cmd}]}')

        echo "overrides=$OVERRIDES" >> $GITHUB_OUTPUT
        echo "container_name=$CONTAINER_NAME" >> $GITHUB_OUTPUT

        # Extract log configuration if present
        LOG_CONFIG=$(echo "$TASK_DEF_JSON" | jq -r '.containerDefinitions[0].logConfiguration // empty')
        if [ ! -z "$LOG_CONFIG" ] && [ "$LOG_CONFIG" != "null" ]; then
          LOG_GROUP=$(echo "$LOG_CONFIG" | jq -r '.options."awslogs-group" // empty')
          LOG_STREAM_PREFIX=$(echo "$LOG_CONFIG" | jq -r '.options."awslogs-stream-prefix" // empty')
          LOG_REGION=$(echo "$LOG_CONFIG" | jq -r '.options."awslogs-region" // empty')
          echo "log_group=$LOG_GROUP" >> $GITHUB_OUTPUT
          echo "log_stream_prefix=$LOG_STREAM_PREFIX" >> $GITHUB_OUTPUT
          echo "log_region=$LOG_REGION" >> $GITHUB_OUTPUT
        fi

    - name: Run ECS task
      id: run-task
      shell: bash
      run: |
        # Run the task with extracted configuration
        TASK_OUTPUT=$(aws ecs run-task \
          --cluster "${{ inputs.cluster_arn }}" \
          --task-definition "${{ steps.service-config.outputs.task_definition }}" \
          --launch-type "${{ steps.service-config.outputs.launch_type }}" \
          --network-configuration '${{ steps.service-config.outputs.network_config }}' \
          --platform-version "${{ steps.service-config.outputs.platform_version }}" \
          --overrides '${{ steps.parse-command.outputs.overrides }}' \
          --output json)

        # Extract task ARN
        TASK_ARN=$(echo "$TASK_OUTPUT" | jq -r '.tasks[0].taskArn')
        echo "task_arn=$TASK_ARN" >> $GITHUB_OUTPUT

        # Extract task ID for log streaming
        TASK_ID=$(echo "$TASK_ARN" | awk -F'/' '{print $NF}')
        echo "task_id=$TASK_ID" >> $GITHUB_OUTPUT

        echo "Started ECS task: $TASK_ARN"

    - name: Stream logs and wait for completion
      id: wait
      if: inputs.wait == 'true'
      shell: bash
      run: |
        TASK_ARN="${{ steps.run-task.outputs.task_arn }}"
        TASK_ID="${{ steps.run-task.outputs.task_id }}"
        CONTAINER_NAME="${{ steps.parse-command.outputs.container_name }}"
        LOG_GROUP="${{ steps.parse-command.outputs.log_group }}"
        LOG_STREAM_PREFIX="${{ steps.parse-command.outputs.log_stream_prefix }}"
        STREAM_LOGS="${{ inputs.stream_logs }}"

        # Function to get task status
        get_task_status() {
          aws ecs describe-tasks \
            --cluster "${{ inputs.cluster_arn }}" \
            --tasks "$TASK_ARN" \
            --query 'tasks[0].lastStatus' \
            --output text
        }

        # Function to check if log stream exists
        check_log_stream() {
          local log_stream="$1"
          aws logs describe-log-streams \
            --log-group-name "$LOG_GROUP" \
            --log-stream-name-prefix "$log_stream" \
            --max-items 1 \
            --output json 2>/dev/null | jq -e '.logStreams | length > 0' > /dev/null 2>&1
        }

        # Construct log stream name
        LOG_STREAM="${LOG_STREAM_PREFIX}/${CONTAINER_NAME}/${TASK_ID}"
        LOGS_SEEN=false
        LAST_TOKEN=""
        LAST_STATUS=""
        TIMEOUT="${{ inputs.timeout }}"
        START_TIME=$(date +%s)

        # Wait for task to complete
        echo "Waiting for task to complete..."
        while true; do
          # Stream logs if enabled (skip during PROVISIONING/PENDING to avoid missing early logs)
          if [ "$STREAM_LOGS" == "true" ] && [ ! -z "$LOG_GROUP" ] && [ "$LOG_GROUP" != "null" ] && \
             [ "$LAST_STATUS" != "PROVISIONING" ] && [ "$LAST_STATUS" != "PENDING" ] && [ ! -z "$LAST_STATUS" ]; then
            if check_log_stream "$LOG_STREAM"; then
              if [ "$LOGS_SEEN" == "false" ]; then
                echo "Log stream available, streaming logs..."
                LOGS_SEEN=true
              fi

              # Get new logs
              if [ -z "$LAST_TOKEN" ]; then
                LOG_OUTPUT=$(aws logs get-log-events \
                  --log-group-name "$LOG_GROUP" \
                  --log-stream-name "$LOG_STREAM" \
                  --start-from-head \
                  --output json 2>/dev/null)
              else
                LOG_OUTPUT=$(aws logs get-log-events \
                  --log-group-name "$LOG_GROUP" \
                  --log-stream-name "$LOG_STREAM" \
                  --next-token "$LAST_TOKEN" \
                  --output json 2>/dev/null)
              fi

              if [ ! -z "$LOG_OUTPUT" ]; then
                # Display new events
                echo "$LOG_OUTPUT" | jq -r '.events[] | "\(.message)"' 2>/dev/null || true

                # Update token
                NEW_TOKEN=$(echo "$LOG_OUTPUT" | jq -r '.nextForwardToken' 2>/dev/null)
                if [ "$NEW_TOKEN" != "$LAST_TOKEN" ]; then
                  LAST_TOKEN="$NEW_TOKEN"
                fi
              fi
            fi
          fi

          STATUS=$(get_task_status)
          if [ "$STATUS" != "$LAST_STATUS" ]; then
            LAST_STATUS="$STATUS"
            echo "Task status: $STATUS"
          fi

          # Check timeout
          if [ "$TIMEOUT" != "0" ]; then
            ELAPSED=$(($(date +%s) - START_TIME))
            if [ "$ELAPSED" -gt "$TIMEOUT" ]; then
              echo "::error::Task timed out after ${TIMEOUT}s"

              # Stop the task
              aws ecs stop-task \
                --cluster "${{ inputs.cluster_arn }}" \
                --task "$TASK_ARN" \
                --reason "Timeout after ${TIMEOUT}s"

              exit 1
            fi
          fi

          if [ "$STATUS" == "STOPPED" ]; then
            break
          fi

          sleep 3
        done

        # Check task exit code
        TASK_DETAILS=$(aws ecs describe-tasks \
          --cluster "${{ inputs.cluster_arn }}" \
          --tasks "$TASK_ARN" \
          --output json)

        EXIT_CODE=$(echo "$TASK_DETAILS" | jq -r '.tasks[0].containers[0].exitCode // -1')
        STOP_CODE=$(echo "$TASK_DETAILS" | jq -r '.tasks[0].stopCode // "Unknown"')
        STOPPED_REASON=$(echo "$TASK_DETAILS" | jq -r '.tasks[0].stoppedReason // "No reason provided"')

        echo "Task completed with exit code: $EXIT_CODE"
        echo "Stop code: $STOP_CODE"
        echo "Stopped reason: $STOPPED_REASON"

        # If logs weren't streamed, show them now
        if [ "$STREAM_LOGS" == "false" ] && [ ! -z "$LOG_GROUP" ] && [ "$LOG_GROUP" != "null" ]; then
          echo "=== Task Logs ==="
          aws logs get-log-events \
            --log-group-name "$LOG_GROUP" \
            --log-stream-name "$LOG_STREAM" \
            --start-from-head \
            --output json \
            2>/dev/null | jq -r '.events[].message' || echo "Logs not available"
        fi

        # Fail if task failed
        echo "exit_code=$EXIT_CODE" >> $GITHUB_OUTPUT
        if [ "$EXIT_CODE" != "0" ]; then
          echo "::error::Task failed with exit code $EXIT_CODE"
          exit 1
        fi
